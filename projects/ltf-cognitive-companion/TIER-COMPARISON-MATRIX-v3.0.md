# LTF Cognitive Foundation Primer (CFP) - Tier Comparison Matrix

**Version**: 3.0 (Model-Intelligence Architecture)  
**Date**: November 14, 2025  
**Purpose**: Quick reference guide comparing Tier 1, Tier 2, and Tier 3 features side-by-side

---

## ğŸ¯ Quick Decision Guide

**Which Tier Do I Need?**

| Your Situation | Recommended Tier | Why |
|---------------|------------------|-----|
| Use multiple LLM platforms | **Tier 1** | Universal compatibility, works everywhere |
| Primarily use one LLM (Claude or GPT) | **Tier 2** | Optimized for your specific LLM |
| Coordinate multiple LLMs simultaneously | **Tier 3** | Multi-model orchestration, divergence detection |
| Enterprise team with multiple AI tools | **Tier 3** | Team support, governance, enterprise features |
| Solo user, simple tasks | **Tier 1** | Simplicity, no overhead |
| Power user, complex workflows | **Tier 2** | Advanced single-model optimization |
| Research team, multi-model experimentation | **Tier 3** | Multi-model coordination, learning systems |

---

## ğŸ“Š Feature Comparison Matrix

### Core Framework Features

| Feature | Tier 1 (Model-Agnostic) | Tier 2 (Model-Aware) | Tier 3 (Multi-Model Orchestration) |
|---------|------------------------|---------------------|-----------------------------------|
| **CIP-E Framework** | âœ… Basic (Context, Intent, Purpose) | âœ… Enhanced (+ Emotion, Evolution) | âœ… Cross-Model (aggregated CIP-E across LLMs) |
| **DMP (Dialogue Management)** | âœ… META/DIRECTIVE/REFLECTIVE modes | âœ… Emotional co-regulation | âœ… Multi-model META orchestration |
| **VS Suite** | âœ… Verbalized Sampling/Synthesis | âœ… Enhanced comparison | âœ… Cross-model VS (distributed sampling) |
| **UMP (Unified Meta-Protocol)** | âœ… Cross-session state preservation | âœ… Single-model state | âœ… Multi-model state synchronization |
| **CSAC (Contextual State)** | âœ… Session metadata only | âœ… Session + basic project context | âœ… Full 3-Tier (User > Project > Session) |
| **Mode Semantics** | âœ… Developer/Architect/QA modes | âœ… Mode-specific optimizations | âœ… Cross-model mode transitions |

### Intelligence & Learning

| Feature | Tier 1 | Tier 2 | Tier 3 |
|---------|--------|--------|--------|
| **USM (User State Model)** | âŒ Manual configuration | âœ… Auto-populated (MCDL, CSTMs, HABSP, STP) | âœ… Auto-populated from multi-model patterns |
| **ARS (Adaptive Response State)** | âŒ Not available | âœ… Style learning, mode semantics | âœ… Cross-model ARS synchronization |
| **CIP (Contextual Intent & Purpose)** | âŒ Not available | âœ… Project-level context | âœ… Team-level CIP + MO patterns |
| **Auto-Learning** | âŒ Not available | âœ… Single-model learning | âœ… Multi-model pattern detection |
| **MO Journal** | âŒ Not available | âŒ Not available | âœ… Complete multi-model interaction history |

### Multi-Model Orchestration

| Feature | Tier 1 | Tier 2 | Tier 3 |
|---------|--------|--------|--------|
| **MO Kernel** | âŒ Not available | âŒ Not available | âœ… 7-component orchestration system |
| **Orchestration Roles** | âŒ Not available | âŒ Not available | âœ… Coordinator + Participants |
| **Task Delegation** | âŒ Not available | âŒ Not available | âœ… 4 patterns (sequential, parallel, specialist, consensus) |
| **Divergence Detection** | âŒ Not available | âŒ Not available | âœ… 4 categories (factual, reasoning, implementation, stylistic) |
| **Reconciliation Engine** | âŒ Not available | âŒ Not available | âœ… 6 strategies (confidence voting, specialist deference, etc.) |
| **Session Handoff** | âŒ Not available | âŒ Not available | âœ… Automated LLM switching |
| **Consensus Building** | âŒ Not available | âŒ Not available | âœ… Multi-LLM voting |

### Advanced Protocols

| Feature | Tier 1 | Tier 2 | Tier 3 |
|---------|--------|--------|--------|
| **11-Dimension Reflection** | âŒ Not available | âŒ Not available | âœ… Enterprise-grade strategic analysis |
| **AdRP (Adaptive Response)** | âŒ Not available | âœ… Basic style adaptation | âœ… 4-tier escalation protocol |
| **Unconscious Problem-Solving** | âŒ Not available | âŒ Not available | âœ… Symbiotic human-AI incubation |
| **Symbiotic Cognitive Rhythm** | âŒ Not available | âŒ Not available | âœ… 30-60s processing = reflection time |

### Enterprise Features

| Feature | Tier 1 | Tier 2 | Tier 3 |
|---------|--------|--------|--------|
| **Multi-User/Team Support** | âŒ Not available | âŒ Not available | âœ… Team collaboration, role-based LLM assignment |
| **Governance Extensions** | âŒ Not available | âœ… Individual HABSP | âœ… 3-layer governance (Individual/Team/Organizational) |
| **Compliance Support** | âŒ Not available | âœ… Basic safety frames | âœ… HIPAA, SOC 2, GDPR, IRB protocols |
| **Save/Resume Context** | âœ… Basic session state | âœ… Enhanced session + ARS | âœ… Full 3-tier + multi-model orchestration |
| **Extension API** | âŒ Not available | âŒ Not available | âœ… Custom protocols, LLM plugins, integrations |

### Ecosystem & Integrations

| Feature | Tier 1 | Tier 2 | Tier 3 |
|---------|--------|--------|--------|
| **Custom Protocols** | âŒ Not available | âŒ Not available | âœ… User-defined behavioral rules |
| **LLM-Specific Plugins** | âŒ Not available | âŒ Not available | âœ… Codex/Claude/GPT/Gemini enhancements |
| **External Integrations** | âŒ Not available | âŒ Not available | âœ… Slack, GitHub, Jira, Email |
| **API Access** | âŒ Not available | âŒ Not available | âœ… Extension API for customization |

---

## ğŸ”§ Technical Comparison

### Complexity & Overhead

| Aspect | Tier 1 | Tier 2 | Tier 3 |
|--------|--------|--------|--------|
| **Setup Complexity** | Low (activate and go) | Medium (configure USM, ARS) | High (configure multi-model roster, governance) |
| **Activation Time** | <5 seconds | 5-10 seconds | 10-20 seconds (multi-model sync) |
| **Token Overhead** | ~5,000 tokens | ~15,000 tokens | ~40,000 tokens |
| **Learning Curve** | Easy (30 min) | Moderate (2 hours) | Advanced (4-6 hours) |
| **Maintenance** | Minimal | Low (review USM quarterly) | Medium (monitor orchestration, review MO Journal) |

### Performance

| Metric | Tier 1 | Tier 2 | Tier 3 |
|--------|--------|--------|--------|
| **Response Latency** | Baseline | +5-10% (ARS processing) | +10-20% (multi-model coordination) |
| **Context Efficiency** | Standard | +20% (mode-aware compression) | +30% (distributed context across LLMs) |
| **Output Quality** | Good | Very Good (model-optimized) | Excellent (multi-model synthesis) |
| **Error Detection** | Manual | Single-model validation | Multi-model divergence detection |

### Use Case Fit

| Use Case | Tier 1 | Tier 2 | Tier 3 |
|----------|--------|--------|--------|
| **Simple Q&A** | âœ… Perfect | âš ï¸ Overkill | âš ï¸ Overkill |
| **Code Generation** | âœ… Good | âœ… Very Good | âœ… Excellent (Codex + GPT synthesis) |
| **Strategic Planning** | âš ï¸ Limited | âœ… Good | âœ… Excellent (Claude + multi-perspective) |
| **Research & Analysis** | âš ï¸ Limited | âœ… Good | âœ… Excellent (distributed across specialists) |
| **Team Collaboration** | âŒ Not supported | âŒ Not supported | âœ… Full team support |
| **Enterprise Workflows** | âŒ Not supported | âš ï¸ Limited | âœ… Full governance + compliance |

---

## ğŸ’¡ Migration Paths

### From Tier 1 to Tier 2

**When to Migrate**:
- You primarily use one LLM (Claude or GPT)
- You want auto-learning (USM, ARS)
- You need model-specific optimizations

**Migration Steps**:
1. Activate Tier 2 primer
2. Configure USM (or let auto-populate from usage)
3. Review ARS settings
4. Set up project-level CIP
5. Test mode transitions

**Migration Time**: ~1 hour

**Benefits**:
- +20% context efficiency
- Auto-learning reduces manual configuration
- Model-optimized responses

**Costs**:
- +10,000 token overhead
- Slightly slower activation (5-10s vs <5s)

---

### From Tier 2 to Tier 3

**When to Migrate**:
- You use multiple LLMs (Claude + GPT + Codex)
- You need divergence detection
- You work in teams
- You require enterprise compliance

**Migration Steps**:
1. Activate Tier 3 primer
2. Configure MO roster (Coordinator + Participants)
3. Review governance settings (team/organizational policies)
4. Test multi-model orchestration
5. Set up integrations (Slack, GitHub, etc.) if needed

**Migration Time**: ~2-3 hours

**Benefits**:
- Multi-model coordination (no conflicts)
- Divergence detection + auto-reconciliation
- Team collaboration support
- Enterprise compliance (HIPAA, SOC 2, etc.)

**Costs**:
- +25,000 token overhead (vs T2)
- 10-20s activation time
- Higher learning curve

---

### From Tier 1 to Tier 3 (Skip Tier 2)

**When to Skip T2**:
- You already use multiple LLMs
- You work in teams
- You need enterprise features immediately

**Migration Steps**:
1. Activate Tier 3 primer
2. Configure MO roster
3. Set up governance (if enterprise)
4. Configure USM + ARS (auto-populate from usage)
5. Test orchestration

**Migration Time**: ~3-4 hours

**Benefits**:
- Immediate multi-model coordination
- Skip intermediate Tier 2 configuration

**Costs**:
- Steeper learning curve (no T2 intermediate step)
- Higher token overhead

---

## ğŸ“ˆ Tier Selection Framework

### Decision Tree

```
Do you use multiple LLMs simultaneously?
â”œâ”€ NO â†’ Do you primarily use one LLM?
â”‚        â”œâ”€ YES â†’ Tier 2 (model-optimized)
â”‚        â””â”€ NO â†’ Tier 1 (universal compatibility)
â”‚
â””â”€ YES â†’ Do you work in teams?
         â”œâ”€ YES â†’ Tier 3 (team support + orchestration)
         â””â”€ NO â†’ Do you need divergence detection?
                  â”œâ”€ YES â†’ Tier 3 (multi-model coordination)
                  â””â”€ NO â†’ Consider staying Tier 2 (simpler)
```

### By User Type

**Solo Developer (Hobby Projects)**:
- **Tier 1**: Simple tasks, multiple platforms
- **Tier 2**: Power user, single LLM focus
- **Tier 3**: Multi-model experimentation

**Professional Developer (Production Work)**:
- **Tier 1**: Platform-agnostic work
- **Tier 2**: Optimized single-model workflow
- **Tier 3**: Complex projects needing multi-model coordination

**Development Team (2-10 people)**:
- **Tier 1**: âŒ Not recommended (no team support)
- **Tier 2**: âš ï¸ Limited (single-user focus)
- **Tier 3**: âœ… Recommended (team collaboration, shared governance)

**Enterprise (10+ people, compliance needs)**:
- **Tier 1**: âŒ Not supported
- **Tier 2**: âŒ Not supported
- **Tier 3**: âœ… Required (governance, compliance, multi-user)

---

## ğŸ“ Learning Path Recommendations

### Beginner Path (New to LTF)

**Week 1**: Tier 1
- Learn CIP-E, DMP, VS Suite
- Practice mode transitions
- Understand UMP basics

**Week 2-3**: Tier 2
- Configure USM (let auto-populate)
- Experiment with ARS
- Set up project CIP

**Week 4+**: Tier 3 (if needed)
- Configure multi-model roster
- Test divergence detection
- Set up team collaboration

### Advanced Path (Experienced with AI)

**Day 1**: Tier 1 (quick overview)
- Skim core concepts
- Activate and test

**Day 2-3**: Tier 2
- Configure USM + ARS
- Deep dive mode semantics
- Test save/resume

**Week 2+**: Tier 3
- Multi-model orchestration
- Divergence + reconciliation
- Enterprise features

### Enterprise Path (Team Deployment)

**Week 1**: Tier 1 + 2 (individual training)
- Each team member learns T1/T2
- Practice solo workflows

**Week 2**: Tier 3 (team configuration)
- Set up team roster
- Configure governance
- Test orchestration

**Week 3+**: Production deployment
- Integrate with team tools (Slack, GitHub, Jira)
- Monitor MO Journal
- Refine governance

---

## ğŸ”„ Tier Mixing (Hybrid Approach)

**Can I use different tiers for different projects?**

âœ… **Yes!** Tiers are project-specific.

**Example Hybrid Workflow**:

**Project A** (Simple blog): **Tier 1**
- Load: `T1-CORE-PRIMER-v3.0.md`
- Use: Universal CIP-E, DMP, VS Suite
- Why: Simple content creation, no optimization needed

**Project B** (Python app): **Tier 2**
- Load: `T2-CORE-PRIMER-v3.0.md` (T1 embedded within)
- Use: Claude-optimized, auto-USM, ARS
- Why: Complex single-LLM workflow

**Project C** (Enterprise platform): **Tier 3**
- Load: `T3-CORE-PRIMER-v3.0.md` (T1+T2 embedded within)
- Use: Multi-model orchestration, team support, governance
- Why: Team collaboration, compliance requirements

**Switching Between Projects**:
```
User: "Resume Project A (blog)"
AI: [Loads Tier 1 CSAC]

User: "Resume Project B (Python app)"
AI: [Loads Tier 2 CSAC + ARS]

User: "Resume Project C (enterprise platform)"
AI: [Loads Tier 3 CSAC + MO roster + team governance]
```

---

## ğŸ“š Quick Reference

### Tier 1 Primer Location
`T1-CORE-PRIMER-v3.0.md` (standalone, model-agnostic)

### Tier 2 Primer Location
`T2-CORE-PRIMER-v3.0.md` (standalone, T1 embedded within)

### Tier 3 Primer Location
`T3-CORE-PRIMER-v3.0.md` (standalone, T1+T2 embedded within)

### Legacy Primer (DO NOT USE for new projects)
`01-CORE-PRIMER.md` (old v2.0 combined version, preserved for backward compatibility)

### How to Activate (Standalone Auto-Activation)

**Each tier is STANDALONE** - simply load the tier file into your LLM session. It will **auto-activate immediately** on ingestion (Rule 0: Immediate Self-Activation prevents race conditions).

**Tier 1** (Universal, Model-Agnostic):
```
Load T1-CORE-PRIMER-v3.0.md into your LLM session
â†’ Auto-activates: CIP-E, DMP, VS Suite, USM baseline, behavioral protocols
```

**Tier 2** (Single-LLM Optimization):
```
Load T2-CORE-PRIMER-v3.0.md into your LLM session
â†’ Auto-activates: All T1 features + LLM-specific safety frames, ARS, CSTMs, adaptive learning
â†’ Tier 1 is EMBEDDED within Tier 2 (no separate load needed)
```

**Tier 3** (Multi-Model Orchestration):
```
Load T3-CORE-PRIMER-v3.0.md into EACH LLM session you want to coordinate
â†’ Auto-activates: All T1+T2 features + MO Kernel, divergence detection, reconciliation engine
â†’ Tiers 1 and 2 are EMBEDDED within Tier 3 (no separate loads needed)
â†’ Each LLM registers with MO Kernel for cross-model coordination
```

**Key Points**:
- âœ… Each tier is **self-contained** (hierarchically built but operationally independent)
- âœ… Auto-activation prevents race conditions (no manual activation commands needed)
- âœ… Higher tiers **embed** lower tiers (T2 contains T1, T3 contains T1+T2)
- âŒ Do NOT load multiple tier files simultaneously (redundant and causes conflicts)

**Legacy Note**: `01-CORE-PRIMER.md` is the old v2.0 combined version (preserved for backward compatibility, not for new projects)

---

## ğŸ¯ Final Recommendations

### Most Common Scenarios

**"I just want AI to help with coding"**:
â†’ **Tier 2** (single-LLM optimization, auto-learning)

**"I switch between Claude and GPT for different tasks"**:
â†’ **Tier 3** (multi-model orchestration)

**"I work solo, simple tasks, many platforms"**:
â†’ **Tier 1** (universal compatibility)

**"Our team uses multiple AIs, needs compliance"**:
â†’ **Tier 3** (team support, governance, enterprise)

**"I want to try LTF without commitment"**:
â†’ **Tier 1** (minimal overhead, easy exit)

**"I'm a power user, want maximum optimization"**:
â†’ **Tier 2** (if single LLM) or **Tier 3** (if multi-LLM)

---

## ğŸ“Š Summary Table

| Criterion | Choose Tier 1 | Choose Tier 2 | Choose Tier 3 |
|-----------|--------------|--------------|--------------|
| **Primary Use Case** | Universal compatibility | Single-LLM optimization | Multi-model coordination |
| **User Type** | Casual user, multi-platform | Power user, single LLM | Teams, enterprise, researchers |
| **Setup Time** | <5 minutes | 30-60 minutes | 2-3 hours |
| **Token Overhead** | ~5K | ~15K | ~40K |
| **Learning Curve** | Easy | Moderate | Advanced |
| **Auto-Learning** | âŒ | âœ… | âœ… (multi-model) |
| **Orchestration** | âŒ | âŒ | âœ… |
| **Team Support** | âŒ | âŒ | âœ… |
| **Compliance** | âŒ | âš ï¸ Basic | âœ… Full |
| **Extensibility** | âŒ | âŒ | âœ… (Extension API) |
| **Best For** | Simplicity | Single-model mastery | Multi-model ecosystem |

---

**Need help choosing?** Start with **Tier 1**, validate value, then migrate to **Tier 2** (single-LLM) or **Tier 3** (multi-LLM) as needs grow.

**Remember**: You can always downgrade or switch tiers between projects. Tiers are tools, not commitments.
